{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34Y7H7bSBtwt",
        "outputId": "285a57b2-602d-45cf-e2aa-77184b25da63"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BOwGSXBfBsg4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.regression.mixed_linear_model import MixedLM\n",
        "from sklearn.metrics.pairwise import euclidean_distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "N4vwMQRvBsg6"
      },
      "outputs": [],
      "source": [
        "# load in the data\n",
        "genotypes = pd.read_csv('/content/drive/My Drive/comp_gen/Genotypic_data_maf10_min10_291acc.txt', index_col=0)\n",
        "phenotype = pd.read_csv('/content/drive/My Drive/comp_gen/phenodata_BLUP_2012.txt', sep='\\t', index_col='ID')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oWT3TWWjBsg6"
      },
      "outputs": [],
      "source": [
        "def calculate_maf(df):\n",
        "    # Calculate minor allele frequency\n",
        "    maf = df.apply(lambda x: min(x.mean(), 1-x.mean()), axis=0)\n",
        "    return maf\n",
        "\n",
        "def ld_pruning(df, threshold=0.5):\n",
        "    # Calculate correlation matrix\n",
        "    corr = df.corr()\n",
        "    # Identify pairs of SNPs with correlation greater than the threshold\n",
        "    # Avoid double removal and self-comparison (i.e., diagonal elements)\n",
        "    to_remove = set()\n",
        "    for i in range(corr.shape[0]):\n",
        "        for j in range(i+1, corr.shape[0]):\n",
        "            if corr.iloc[i, j] > threshold:\n",
        "                to_remove.add(corr.columns[j])\n",
        "    return df.drop(columns=to_remove)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "v5K7t2n8Bsg6"
      },
      "outputs": [],
      "source": [
        "# Apply MAF filtering\n",
        "maf = calculate_maf(genotypes)\n",
        "maf_threshold = 0.01  # Set MAF threshold\n",
        "genotypes_filtered = genotypes.loc[:, maf >= maf_threshold]\n",
        "\n",
        "# Apply LD pruning\n",
        "genotypes_pruned = ld_pruning(genotypes_filtered, threshold=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IrXQ4UaxBsg7"
      },
      "outputs": [],
      "source": [
        "# 'genotypes' and 'phenotype' are already loaded and aligned by their indices\n",
        "# now we check for missing data\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "genotypes_imputed = pd.DataFrame(imputer.fit_transform(genotypes_pruned), columns=genotypes_pruned.columns)\n",
        "phenotype_imputed = pd.DataFrame(imputer.fit_transform(phenotype), columns=phenotype.columns)\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "genotypes_scaled = pd.DataFrame(scaler.fit_transform(genotypes_imputed), columns=genotypes_pruned.columns)\n",
        "\n",
        "# Check for any remaining NaNs or infinities\n",
        "genotypes_scaled = genotypes_scaled.replace([np.inf, -np.inf], np.nan).dropna(axis=1)\n",
        "phenotype_scaled = pd.DataFrame(scaler.fit_transform(phenotype_imputed), columns=phenotype.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYj5PNLvBsg7",
        "outputId": "93b34932-e609-4932-e89e-0435ae4d9c17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 291\n",
            "Number of features: 243\n"
          ]
        }
      ],
      "source": [
        "# Extract the AVGROW97 column from the phenotype dataframe\n",
        "y = phenotype_scaled['AVGROW97']\n",
        "# Construct X from the genotype dataframe\n",
        "X = genotypes_scaled\n",
        "\n",
        "# Determine the number of samples (rows) and features (columns)\n",
        "num_samples, num_features = X.shape\n",
        "\n",
        "print(f\"Number of samples: {num_samples}\")\n",
        "print(f\"Number of features: {num_features}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EZ1CBDhBsg7"
      },
      "source": [
        "### 4. Random Forest Feature Selection with Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "t7aE2DY1Bsg8"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "\n",
        "est = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
        "y_binned = est.fit_transform(y.values.reshape(-1, 1)).ravel()\n",
        "\n",
        "\n",
        "# Random Forest hyperparameters grid\n",
        "rf_params = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "}\n",
        "\n",
        "# Randomized search with cross-validation\n",
        "rf_random_search = RandomizedSearchCV(RandomForestClassifier(random_state=0),\n",
        "                                      rf_params, n_iter=10, cv=5, random_state=0, error_score='raise')\n",
        "rf_random_search.fit(X, y_binned)\n",
        "selected_features_rf = np.argsort(rf_random_search.best_estimator_.feature_importances_)[::-1]\n",
        "# Save selected features from Random Forest\n",
        "np.savetxt(\"selected_features_rf.txt\", selected_features_rf, fmt='%d')\n",
        "# Random Forest feature importances\n",
        "np.savetxt(\"random_forest_importances.txt\", rf_random_search.best_estimator_.feature_importances_, fmt='%f')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the files to your local system\n",
        "files.download('selected_features_rf.txt')\n",
        "files.download('random_forest_importances.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "BAemM2ZdHEjq",
        "outputId": "74c2896c-6aed-4bda-9594-900cf90f9a15"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_daf97dc1-0f1b-4000-b5f3-5369c0bbf955\", \"selected_features_rf.txt\", 862)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_aa094281-03ae-4e72-92e0-da806f27e771\", \"random_forest_importances.txt\", 2187)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "3b7e9cb8e453d6cda0fe8c8dd13f891a1f09162f0e7c66ffeae7751a7aecf00d"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}